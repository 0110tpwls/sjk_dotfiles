[project]
authors = ["0110tpwls <0110tpwls@gmail.com>"]
channels = ["https://prefix.dev/conda-forge", "conda-forge"]
description = "Baseline environment for LLM and lVLM"
name = "llm-baseline"
platforms = ["linux-64"]
version = "0.1.0"

[system-requirements]
cuda = "12.5"

[tasks]

[dependencies]
python = ">=3.11"
pytorch-gpu = "*"
cuda-version = ">=12.4"
numpy = ">=1.26.0, <2"
torchvision = ">=0.19.1,<=0.20.1"
fsspec = ">=2023.1.0,<=2024.9.0"

[pypi-options]
no-build-isolation = ["flash-attn"]

[pypi-dependencies]
vllm = "*"
flash-attn = "*"
accelerate = ">=1.3.0, <2"
bitsandbytes = ">=0.45.2, <0.46"
transformers = ">=4.48.3, <5"
jupyter = ">=1.1.1, <2"
datasets = ">=2.14.4, <3"
hf-transfer = ">=0.1.9, <0.2"


=====================================================

[system-requirements]
cuda = "12"

[dependencies]
# We need a python version that is compatible with pytorch
python = ">=3.11,<3.13"

[pypi-options]
no-build-isolation = ["flash-attn"]

[pypi-dependencies]
numpy = ">=1.26.0, <2"
fsspec = ">=2023.1.0,<=2024.9.0"
torch = { version = ">=2.5.1", index = "https://download.pytorch.org/whl/cu124" }
torchvision = { version = ">=0.20.1", index = "https://download.pytorch.org/whl/cu124" }
flash-attn = "==2.7.3"
vllm = ">=0.7"